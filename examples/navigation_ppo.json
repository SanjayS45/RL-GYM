{
  "name": "Navigation PPO Example",
  "description": "Train a PPO agent to navigate continuously with lidar sensors",
  "environment": {
    "type": "navigation",
    "width": 20.0,
    "height": 20.0,
    "num_rays": 16,
    "max_speed": 2.0,
    "seed": 42
  },
  "agent": {
    "algorithm": "ppo",
    "learning_rate": 0.0003,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_epsilon": 0.2,
    "value_coef": 0.5,
    "entropy_coef": 0.01,
    "n_steps": 2048,
    "n_epochs": 10,
    "batch_size": 64,
    "max_grad_norm": 0.5,
    "hidden_dims": [256, 256]
  },
  "training": {
    "total_timesteps": 100000,
    "eval_freq": 2000,
    "log_freq": 100,
    "save_freq": 10000,
    "render_freq": 5
  }
}

